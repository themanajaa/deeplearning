{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a54c22",
   "metadata": {},
   "source": [
    "# Projet 2 - NLP : Génération de texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37589ae3",
   "metadata": {},
   "source": [
    "## Étape 1 : Préparation du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mmf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Importer les librairies\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "\n",
    "# Télécharger les ressources NLTK si besoin\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu du corpus :\n",
      "Two roads diverged in a yellow wood,\n",
      "And sorry I could not travel both\n",
      "And be one traveler, long I stood\n",
      "And looked down one as far as I could\n",
      "To where it bent in the undergrowth;\n",
      "\n",
      "I wandered lonely as a cloud\n",
      "That floats on high o'er vales and hills,\n",
      "When all at once I saw a crowd,\n",
      "A host, of golden daffodils;\n",
      "Beside the lake, beneath the trees,\n",
      "Fluttering and dancing in the breeze.\n",
      "\n",
      "Hope is the thing with feathers\n",
      "That perches in the soul,\n",
      "And sings the tune without the words,\n",
      "And never stops \n"
     ]
    }
   ],
   "source": [
    "#2. Charger et prévisualiser le corpus\n",
    "with open('data/poems.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(\"Aperçu du corpus :\")\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fff9fc9",
   "metadata": {},
   "source": [
    "## Étape 2 : Tokenisation et vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tokens : 153\n",
      "Premiers 20 tokens : ['Two', 'roads', 'diverged', 'in', 'a', 'yellow', 'wood', ',', 'And', 'sorry', 'I', 'could', 'not', 'travel', 'both', 'And', 'be', 'one', 'traveler', ',']\n"
     ]
    }
   ],
   "source": [
    "#3. Tokenisation\n",
    "tokens = word_tokenize(text)\n",
    "print(f\"Nombre de tokens : {len(tokens)}\")\n",
    "print(f\"Premiers 20 tokens : {tokens[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire : 101\n",
      "Indices exemple : [17, 69, 40, 51, 19, 99, 97, 0, 6, 75]\n"
     ]
    }
   ],
   "source": [
    "# 4. Construire le vocabulaire et les mappings\n",
    "vocab = sorted(set(tokens))\n",
    "print(f\"Taille du vocabulaire : {len(vocab)}\")\n",
    "\n",
    "token_to_idx = {tok: idx for idx, tok in enumerate(vocab)}\n",
    "idx_to_token = {idx: tok for tok, idx in token_to_idx.items()}\n",
    "\n",
    "# Exemple de conversion tokens → indices\n",
    "indices = [token_to_idx[tok] for tok in tokens[:10]]\n",
    "print(f\"Indices exemple : {indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 tokens les plus fréquents : [(',', 10), ('the', 9), ('And', 6), ('I', 6), ('a', 5), ('in', 4), ('as', 3), (';', 3), ('and', 3), ('all', 3)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Analyse simple : fréquence des tokens\n",
    "counter = Counter(tokens)\n",
    "most_common = counter.most_common(10)\n",
    "print(\"10 tokens les plus fréquents :\", most_common)\n",
    "\n",
    "words, counts = zip(*most_common)\n",
    "plt.bar(words, counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple d'entrée (indices) : [17, 69, 40, 51, 19]\n",
      "Exemple de cible (index) : 99\n"
     ]
    }
   ],
   "source": [
    "# 6. Préparer les séquences pour le modèle\n",
    "# Taille des séquences d'entrée\n",
    "seq_length = 5\n",
    "\n",
    "# Conversion complète des tokens en indices\n",
    "indices = [token_to_idx[tok] for tok in tokens]\n",
    "\n",
    "# Préparer les séquences d'entrée (X) et la cible (Y)\n",
    "inputs = []\n",
    "targets = []\n",
    "for i in range(len(indices) - seq_length):\n",
    "    inputs.append(indices[i:i+seq_length])\n",
    "    targets.append(indices[i+seq_length])\n",
    "\n",
    "print(f\"Exemple d'entrée (indices) : {inputs[0]}\")\n",
    "print(f\"Exemple de cible (index) : {targets[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Dataset et DataLoader PyTorch\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.inputs[idx]), torch.tensor(self.targets[idx])\n",
    "\n",
    "dataset = TextDataset(inputs, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Définir un modèle RNN simple\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        out, _ = self.rnn(embedded)\n",
    "        out = out[:, -1, :]  # dernière sortie RNN\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 32\n",
    "hidden_dim = 64\n",
    "\n",
    "model = RNNModel(vocab_size, embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 4.6502\n",
      "Epoch 2/5 - Loss: 4.4867\n",
      "Epoch 3/5 - Loss: 4.3378\n",
      "Epoch 4/5 - Loss: 4.2248\n",
      "Epoch 5/5 - Loss: 4.0795\n"
     ]
    }
   ],
   "source": [
    "# 9. Entraînement rapide\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_inputs, batch_targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte généré :\n",
      "Two roads diverged in a yellow without ’ date art To temperate perches Fluttering ; too a bent more never To daffodils short Beside it buds And be To stops without wandered one trees once\n"
     ]
    }
   ],
   "source": [
    "# 10. Génération de texte simple\n",
    "def generate_text(model, start_seq, idx_to_token, token_to_idx, length=20):\n",
    "    model.eval()\n",
    "    generated = start_seq.copy()\n",
    "    \n",
    "    for _ in range(length):\n",
    "        # Préparer la séquence en indices\n",
    "        seq_indices = [token_to_idx.get(tok, 0) for tok in generated[-seq_length:]]\n",
    "        seq_tensor = torch.tensor(seq_indices).unsqueeze(0)  # batch=1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(seq_tensor)\n",
    "            prob = nn.functional.softmax(output, dim=1)\n",
    "            next_idx = torch.multinomial(prob, num_samples=1).item()\n",
    "            next_tok = idx_to_token[next_idx]\n",
    "            generated.append(next_tok)\n",
    "    \n",
    "    return ' '.join(generated)\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "start_seq = tokens[:seq_length]\n",
    "print(\"Texte généré :\")\n",
    "print(generate_text(model, start_seq, idx_to_token, token_to_idx, length=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2da34cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de séquences: 148\n",
      "Exemple de séquence (indices): [17, 69, 40, 51, 19]\n",
      "Token cible pour cette séquence: 99 (yellow)\n"
     ]
    }
   ],
   "source": [
    "# Préparer les séquences d’entraînement (input / target) pour génération de texte\n",
    "# Taille des séquences (exemple 5 tokens par séquence)\n",
    "seq_length = 5\n",
    "\n",
    "# Préparer les séquences (X) et les cibles (Y)\n",
    "input_sequences = []\n",
    "target_tokens = []\n",
    "\n",
    "for i in range(len(tokens) - seq_length):\n",
    "    seq_in = tokens[i:i + seq_length]\n",
    "    seq_out = tokens[i + seq_length]\n",
    "    input_sequences.append([token_to_idx[tok] for tok in seq_in])\n",
    "    target_tokens.append(token_to_idx[seq_out])\n",
    "\n",
    "print(f\"Nombre de séquences: {len(input_sequences)}\")\n",
    "print(f\"Exemple de séquence (indices): {input_sequences[0]}\")\n",
    "print(f\"Token cible pour cette séquence: {target_tokens[0]} ({idx_to_token[target_tokens[0]]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dfa408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Créer un Dataset et DataLoader PyTorch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "dataset = TextDataset(input_sequences, target_tokens)\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9524463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définir un modèle RNN simple avec embeddings\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)               # (batch, seq_len, embed_dim)\n",
    "        output, hidden = self.rnn(x)       # output: (batch, seq_len, hidden_dim)\n",
    "        out = self.fc(output[:, -1, :])    # prendre sortie du dernier pas de temps\n",
    "        return out\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 64\n",
    "hidden_dim = 128\n",
    "model = SimpleRNNModel(vocab_size, embed_dim, hidden_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "506b59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurer la fonction de perte et l’optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e131fa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 4.6356\n",
      "Epoch 2/10, Loss: 4.3619\n",
      "Epoch 3/10, Loss: 4.1529\n",
      "Epoch 4/10, Loss: 3.9471\n",
      "Epoch 5/10, Loss: 3.7391\n",
      "Epoch 6/10, Loss: 3.5175\n",
      "Epoch 7/10, Loss: 3.3183\n",
      "Epoch 8/10, Loss: 3.0838\n",
      "Epoch 9/10, Loss: 2.8790\n",
      "Epoch 10/10, Loss: 2.6413\n"
     ]
    }
   ],
   "source": [
    "#Entraîner le modèle (exemple de boucle sur 10 epochs)\n",
    "epochs = 10\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_inputs, batch_targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfcc497d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte généré :\n",
      "Two roads diverged in a yellow wood , And summer ’ s lease hath all too short a date ; , And sings the tune\n"
     ]
    }
   ],
   "source": [
    "#Génération de texte avec le modèle entraîné\n",
    "model.eval()\n",
    "\n",
    "def generate_text(model, start_seq, length=20):\n",
    "    model.eval()\n",
    "    tokens_generated = start_seq.copy()\n",
    "    for _ in range(length):\n",
    "        input_seq = [token_to_idx.get(tok, 0) for tok in tokens_generated[-seq_length:]]\n",
    "        input_tensor = torch.tensor([input_seq], dtype=torch.long)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            predicted_idx = output.argmax(dim=1).item()\n",
    "            tokens_generated.append(idx_to_token[predicted_idx])\n",
    "    return ' '.join(tokens_generated)\n",
    "\n",
    "# Exemple avec une séquence de départ\n",
    "start_sequence = tokens[:seq_length]\n",
    "print(\"Texte généré :\")\n",
    "print(generate_text(model, start_sequence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268b905",
   "metadata": {},
   "source": [
    "## Étape 3 : Embedding + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dff7e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définir un modèle LSTM simple avec embedding\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.lstm(x, hidden)\n",
    "        logits = self.fc(output)\n",
    "        return logits, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e80b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialiser le modèle, optimiser et loss function\n",
    "vocab_size = len(vocab)\n",
    "embed_size = 128\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "\n",
    "model = LSTMModel(vocab_size, embed_size, hidden_size, num_layers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f00b1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement (boucle sur epochs) et Génération de texte avec le modèle entraîné\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fc961e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des séquences (exemple simple)\n",
    "seq_length = 10\n",
    "\n",
    "def create_sequences(tokens, seq_length):\n",
    "    indices = [token_to_idx[t] for t in tokens]\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(len(indices) - seq_length):\n",
    "        inputs.append(indices[i:i+seq_length])\n",
    "        targets.append(indices[i+1:i+seq_length+1])\n",
    "    return torch.tensor(inputs), torch.tensor(targets)\n",
    "\n",
    "inputs, targets = create_sequences(tokens, seq_length)\n",
    "\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "776ccb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation modèle, optimizer, loss (à adapter si déjà défini)\n",
    "vocab_size = len(vocab)\n",
    "embed_size = 128\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "\n",
    "model = LSTMModel(vocab_size, embed_size, hidden_size, num_layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "epochs = 10\n",
    "print_every = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(x_batch)  # output shape: (batch, seq_len, vocab_size)\n",
    "        output = output.view(-1, vocab_size)\n",
    "        y_batch = y_batch.view(-1)\n",
    "\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % print_every == 0:\n",
    "            avg_loss = running_loss / print_every\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Step {i+1}/{len(dataloader)}, Loss: {avg_loss:.4f}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b192ad76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texte généré :\n",
      " Two roads diverged in a wood wood I I I not And travel one traveler traveler long I And be one far long I I And one as as To where where in bent the ; I lonely as That where high o'er bent the , , And I the tune , host , And\n"
     ]
    }
   ],
   "source": [
    "# Génération de texte avec le modèle entraîné\n",
    "model.eval()\n",
    "\n",
    "def generate_text(model, start_text, length=50, temperature=1.0):\n",
    "    model.eval()\n",
    "    tokens_generated = []\n",
    "    input_seq = [token_to_idx.get(t, 0) for t in start_text.split()]\n",
    "    input_seq = input_seq[-seq_length:]  # s'assurer que la séquence est <= seq_length\n",
    "\n",
    "    hidden = None\n",
    "    for _ in range(length):\n",
    "        x = torch.tensor(input_seq).unsqueeze(0).to(device)  # (1, seq_len)\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model(x, hidden)\n",
    "\n",
    "        logits = output[0, -1] / temperature  # logits du dernier token prédit\n",
    "        probs = F.softmax(logits, dim=0).cpu().numpy()\n",
    "        next_token_idx = np.random.choice(len(probs), p=probs)\n",
    "        tokens_generated.append(idx_to_token[next_token_idx])\n",
    "\n",
    "        input_seq.append(next_token_idx)\n",
    "        input_seq = input_seq[1:]  # glisser la fenêtre\n",
    "\n",
    "    return \" \".join(tokens_generated)\n",
    "\n",
    "start_phrase = \"Two roads diverged in a\"\n",
    "generated = generate_text(model, start_phrase, length=50, temperature=0.8)\n",
    "print(\"\\nTexte généré :\\n\", start_phrase + \" \" + generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6a39ad",
   "metadata": {},
   "source": [
    "# Étape 4 : Modèle RNN avec encodage One-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad279fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding shape: torch.Size([4, 5])\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.]])\n",
      "RNN output shape: torch.Size([1, 4, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Exemple de séquence de caractères (indices)\n",
    "sequence = torch.tensor([0, 2, 1, 3])  # exemple d’indices de caractères dans le vocabulaire\n",
    "vocab_size = 5  # taille du vocabulaire\n",
    "\n",
    "# One-hot encoding\n",
    "one_hot = torch.nn.functional.one_hot(sequence, num_classes=vocab_size).float()\n",
    "print(\"One-hot encoding shape:\", one_hot.shape)\n",
    "print(one_hot)\n",
    "\n",
    "# Exemple d’un RNN simple qui prend du one-hot en entrée\n",
    "rnn = nn.RNN(input_size=vocab_size, hidden_size=10, batch_first=True)\n",
    "\n",
    "# Ajouter batch dimension et seq_length dimension (ici batch=1, seq_len=4)\n",
    "input_rnn = one_hot.unsqueeze(0)  # shape (1, seq_len, vocab_size)\n",
    "\n",
    "output, hidden = rnn(input_rnn)\n",
    "\n",
    "print(\"RNN output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8c33d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Exemple de corpus (à remplacer par tes poèmes, citations, etc.)\n",
    "corpus = text.lower()\n",
    "chars = sorted(list(set(corpus)))\n",
    "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i: ch for ch, i in char_to_idx.items()}\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# Dataset utilisant des indices d'entiers (pas de one-hot)\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, text, char_to_idx, seq_len=50):\n",
    "        self.data = [char_to_idx[ch] for ch in text]\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.data[idx:idx+self.seq_len], dtype=torch.long)\n",
    "        y = torch.tensor(self.data[idx+1:idx+self.seq_len+1], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "seq_len = 50\n",
    "dataset = CharDataset(corpus, char_to_idx, seq_len)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3bc33f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_size=256, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # (batch, seq_len, embedding_dim)\n",
    "        output, _ = self.lstm(embedded)\n",
    "        logits = self.fc(output)     # (batch, seq_len, vocab_size)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8ddfc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 3.0761\n",
      "Epoch 2/10 | Loss: 2.5885\n",
      "Epoch 3/10 | Loss: 2.0202\n",
      "Epoch 4/10 | Loss: 1.4501\n",
      "Epoch 5/10 | Loss: 0.8798\n",
      "Epoch 6/10 | Loss: 0.4555\n",
      "Epoch 7/10 | Loss: 0.2404\n",
      "Epoch 8/10 | Loss: 0.1614\n",
      "Epoch 9/10 | Loss: 0.1307\n",
      "Epoch 10/10 | Loss: 0.1143\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CharRNN(vocab_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 10\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_batch)\n",
    "        loss = criterion(output.view(-1, vocab_size), y_batch.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss/len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0392e8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l,\n",
      "ther;:er oke h ollod t oug n bends cind\n",
      "and be ke be be fe in ane s c the an sing ar aratherake athe,\n",
      "ath in ovend g but sthe ou?.\n",
      "th whids wouloi t al,\n",
      "azerind\n",
      "ay ulme ithalodaly\n",
      "and t s ithoutry, \n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_text(model, start_char, char_to_idx, idx_to_char, length=200, temperature=1.0, device='cpu'):\n",
    "    model.eval()\n",
    "    input_idx = torch.tensor([[char_to_idx[start_char]]], dtype=torch.long).to(device)\n",
    "    generated = start_char\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden = None\n",
    "        for _ in range(length):\n",
    "            output = model(input_idx)\n",
    "            logits = output[:, -1, :] / temperature\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_idx = torch.multinomial(probs, num_samples=1).item()\n",
    "            next_char = idx_to_char[next_idx]\n",
    "            generated += next_char\n",
    "            input_idx = torch.tensor([[next_idx]], dtype=torch.long).to(device)\n",
    "\n",
    "    return generated\n",
    "\n",
    "# Exemple\n",
    "print(generate_text(model, start_char='l', char_to_idx=char_to_idx, idx_to_char=idx_to_char, device=device, temperature=0.8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd74e0",
   "metadata": {},
   "source": [
    "Entraîner un tokenizer BPE sur notre corpus (avec SentencePiece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f9fc4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# Entraînement BPE\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input='data/poems.txt',\n",
    "    model_prefix='models/bpe_model',\n",
    "    vocab_size=500,           # tu peux ajuster (plus gros si texte long)\n",
    "    model_type='bpe',         # 'unigram', 'word', etc. aussi dispo\n",
    "    character_coverage=1.0,   # pour texte anglais\n",
    "    bos_id=-1,\n",
    "    eos_id=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d5ff73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Charger le tokenizer pour encoder/décoder du texte\n",
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"models/bpe_model.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfd54cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 107, 226, 257, 30, 2, 250, 217, 474, 46, 230, 54, 78, 185, 80, 202, 46, 65, 72, 259, 474, 211, 54, 231, 46, 246, 206, 72, 43, 182, 43, 54, 78, 70, 236, 153, 201, 30, 7, 264, 485, 54, 260, 245, 43, 2, 221, 5, 20, 243, 155, 208, 12, 489, 3, 235, 46, 223, 474, 156, 34, 45, 64, 212, 54, 187, 2, 222, 474, 2, 209, 474, 67, 244, 261, 485, 18, 193, 7, 210, 474, 251, 7, 234, 474, 39, 313, 240, 46, 253, 30, 7, 242, 487, 28, 137, 152, 7, 233, 77, 258, 5, 20, 255, 30, 7, 213, 474, 46, 229, 7, 215, 256, 7, 238, 474, 46, 225, 232, 64, 45, 487, 68, 372, 54, 252, 214, 70, 2, 79, 488, 468, 180, 491, 5, 16, 178, 76, 247, 46, 76, 262, 490, 112, 169, 237, 149, 227, 7, 254, 203, 67, 56, 276, 474, 46, 79, 488, 468, 224, 207, 45, 188, 228, 2, 205, 485]\n",
      "['▁t', 'wo', '▁roads', '▁diverged', '▁in', '▁a', '▁yellow', '▁wood', ',', '▁and', '▁sorry', '▁i', '▁could', '▁not', '▁travel', '▁both', '▁and', '▁be', '▁one', '▁traveler', ',', '▁long', '▁i', '▁stood', '▁and', '▁looked', '▁down', '▁one', '▁as', '▁far', '▁as', '▁i', '▁could', '▁to', '▁where', '▁it', '▁bent', '▁in', '▁the', '▁undergrowth', ';', '▁i', '▁wandered', '▁lonely', '▁as', '▁a', '▁cloud', '▁th', 'at', '▁floats', '▁on', '▁high', '▁o', \"'\", 'er', '▁vales', '▁and', '▁hills', ',', '▁wh', 'en', '▁all', '▁at', '▁once', '▁i', '▁saw', '▁a', '▁crowd', ',', '▁a', '▁host', ',', '▁of', '▁golden', '▁daffodils', ';', '▁b', 'eside', '▁the', '▁lake', ',', '▁beneath', '▁the', '▁trees', ',', '▁f', 'lu', 'ttering', '▁and', '▁dancing', '▁in', '▁the', '▁breeze', '.', '▁h', 'ope', '▁is', '▁the', '▁thing', '▁with', '▁feathers', '▁th', 'at', '▁perches', '▁in', '▁the', '▁soul', ',', '▁and', '▁sings', '▁the', '▁tune', '▁without', '▁the', '▁words', ',', '▁and', '▁never', '▁stops', '▁at', '▁all', '.', '▁sh', 'all', '▁i', '▁compare', '▁thee', '▁to', '▁a', '▁summer', '’', 's', '▁day', '?', '▁th', 'ou', '▁art', '▁more', '▁lovely', '▁and', '▁more', '▁temperate', ':', '▁r', 'ough', '▁winds', '▁do', '▁shake', '▁the', '▁darling', '▁buds', '▁of', '▁m', 'ay', ',', '▁and', '▁summer', '’', 's', '▁lease', '▁hath', '▁all', '▁too', '▁short', '▁a', '▁date', ';']\n"
     ]
    }
   ],
   "source": [
    "# Tokeniser un texte (→ indices)\n",
    "text = corpus\n",
    "token_ids = sp.encode(text, out_type=int)\n",
    "print(token_ids)  # → [215, 98, 47, ...]\n",
    "tokens = sp.encode(text, out_type=str)\n",
    "print(tokens)  # → ['▁This', '▁is', '▁an', '▁ex', 'ample', ...]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e8f5db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two roads diverged in a yellow wood, and sorry i could not travel both and be one traveler, long i stood and looked down one as far as i could to where it bent in the undergrowth; i wandered lonely as a cloud that floats on high o'er vales and hills, when all at once i saw a crowd, a host, of golden daffodils; beside the lake, beneath the trees, fluttering and dancing in the breeze. hope is the thing with feathers that perches in the soul, and sings the tune without the words, and never stops at all. shall i compare thee to a summer’s day? thou art more lovely and more temperate: rough winds do shake the darling buds of may, and summer’s lease hath all too short a date;\n"
     ]
    }
   ],
   "source": [
    "#Reconstruire le texte à partir des IDs\n",
    "decoded = sp.decode(token_ids)\n",
    "print(decoded)  # → \"This is an example sentence.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88908934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utiliser les IDs comme entrée pour un modèle de génération de texte\n",
    "import torch\n",
    "\n",
    "# Exemple : encode le texte puis convertit en tenseur\n",
    "input_tensor = torch.tensor(token_ids).unsqueeze(0)  # shape (1, seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f4ee9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte généré :\n",
      "▁t wo ▁roads ▁diverged ▁in ▁a ▁yellow ▁wood , ▁and ▁sorry ▁i ▁could ▁not ▁travel ▁both ▁and ▁be ▁one ▁traveler , ▁long ▁i ▁stood ▁and ▁looked ▁down ▁one ▁as ▁far o'er roads the of Two wandered it stops hath could lovely soul That high thing . it lease as too hath crowd sings vales thing ? down could Fluttering a , vales trees That it down trees not Shall roads too wood stops day vales traveler looked a That stops\n"
     ]
    }
   ],
   "source": [
    "#générer du texte à partir d’un start_seq (tokens)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Modèle LSTM simple avec embedding, compatible gestion du hidden state\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.lstm(x, hidden)\n",
    "        logits = self.fc(output)\n",
    "        return logits, hidden\n",
    "\n",
    "\n",
    "# Fonction de génération de texte\n",
    "def generate_text(model, start_seq, idx_to_token, token_to_idx, seq_length, length=50, temperature=1.0):\n",
    "    model.eval()\n",
    "    generated = start_seq.copy()  # liste de tokens\n",
    "\n",
    "    hidden = None  # état initial caché\n",
    "\n",
    "    for _ in range(length):\n",
    "        # Préparer la séquence d'entrée (indices) sur la fenêtre de seq_length\n",
    "        seq_indices = [token_to_idx.get(tok, 0) for tok in generated[-seq_length:]]\n",
    "        seq_tensor = torch.tensor(seq_indices).unsqueeze(0)  # shape (1, seq_length)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits, hidden = model(seq_tensor, hidden)\n",
    "\n",
    "            # Prendre les logits du dernier pas de temps\n",
    "            logits = logits[:, -1, :]  # shape (1, vocab_size)\n",
    "\n",
    "            # Appliquer température\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Softmax pour obtenir une distribution de probas\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "            # Échantillonner le prochain token\n",
    "            next_token_id = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "            # Convertir en token\n",
    "            next_token = idx_to_token[next_token_id]\n",
    "\n",
    "            generated.append(next_token)\n",
    "\n",
    "    return ' '.join(generated)\n",
    "\n",
    "\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embed_size = 128\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "seq_length = 30  # par exemple\n",
    "\n",
    "model = LSTMModel(vocab_size, embed_size, hidden_size, num_layers)\n",
    "\n",
    "start_seq = tokens[:seq_length]\n",
    "\n",
    "generated_text = generate_text(model, start_seq, idx_to_token, token_to_idx, seq_length, length=50, temperature=0.8)\n",
    "\n",
    "print(\"Texte généré :\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "531d69cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokens, token_to_idx, seq_length):\n",
    "        self.token_to_idx = token_to_idx\n",
    "        self.seq_length = seq_length\n",
    "        self.indices = [token_to_idx.get(t, 0) for t in tokens]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Nombre total de séquences\n",
    "        return len(self.indices) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Séquence d'entrée\n",
    "        x = self.indices[idx : idx + self.seq_length]\n",
    "        # Cible = séquence décalée d'un token\n",
    "        y = self.indices[idx + 1 : idx + self.seq_length + 1]\n",
    "        return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "# Paramètres\n",
    "seq_length = 30  # à ajuster\n",
    "\n",
    "# Création dataset & dataloader\n",
    "dataset = TextDataset(tokens, token_to_idx, seq_length)\n",
    "batch_size = 64\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b234a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 4.6121\n",
      "Epoch 2/10 - Loss: 4.6116\n",
      "Epoch 3/10 - Loss: 4.6116\n",
      "Epoch 4/10 - Loss: 4.6121\n",
      "Epoch 5/10 - Loss: 4.6114\n",
      "Epoch 6/10 - Loss: 4.6116\n",
      "Epoch 7/10 - Loss: 4.6120\n",
      "Epoch 8/10 - Loss: 4.6121\n",
      "Epoch 9/10 - Loss: 4.6123\n",
      "Epoch 10/10 - Loss: 4.6118\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits, _ = model(x_batch)  # logits shape: (batch_size, seq_length, vocab_size)\n",
    "\n",
    "        # Reshape pour CrossEntropyLoss : (batch_size * seq_length, vocab_size)\n",
    "        logits = logits.view(-1, vocab_size)\n",
    "        y_batch = y_batch.view(-1)\n",
    "\n",
    "        loss = criterion(logits, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa4dce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/lstm_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0cff842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte généré :\n",
      "▁t wo ▁roads ▁diverged ▁in ▁a ▁yellow ▁wood , ▁and ▁sorry ▁i ▁could ▁not ▁travel ▁both ▁and ▁be ▁one ▁traveler , ▁long ▁i ▁stood ▁and ▁looked ▁down ▁one ▁as ▁far s hath : thee perches yellow high crowd be May lake crowd travel hath words summer floats all . all ? . is of and hath it one cloud roads That hills without be wood once darling stops the lonely s to hath temperate saw tune at , is And\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "start_seq = tokens[:seq_length]  # ou une phrase d’amorce\n",
    "generated_text = generate_text(model, start_seq, idx_to_token, token_to_idx, length=50, temperature=0.8, seq_length=seq_length)\n",
    "\n",
    "print(\"Texte généré :\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a0c97d",
   "metadata": {},
   "source": [
    "Autoencodeur : Définir un modèle Seq2Seq simple avec LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "961f5207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Seq2SeqAutoencoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.decoder = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        # Embedding\n",
    "        embedded_src = self.embedding(src)  # (B, T, E)\n",
    "        embedded_tgt = self.embedding(tgt)  # (B, T, E)\n",
    "        \n",
    "        # Encoder\n",
    "        _, (hidden, cell) = self.encoder(embedded_src)\n",
    "\n",
    "        # Decoder avec le hidden + cell du encodeur\n",
    "        decoder_outputs, _ = self.decoder(embedded_tgt, (hidden, cell))\n",
    "\n",
    "        # Output vocab logits\n",
    "        logits = self.output_layer(decoder_outputs)  # (B, T, vocab_size)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c2443",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = ['<bos>', '<eos>', '<unk>']\n",
    "\n",
    "for token in special_tokens:\n",
    "    if token not in token_to_idx:\n",
    "        idx = len(token_to_idx)\n",
    "        token_to_idx[token] = idx\n",
    "        idx_to_token[idx] = token\n",
    "\n",
    "src_seq = [token_to_idx.get(tok, token_to_idx['<unk>']) for tok in tokens]\n",
    "tgt_seq = [token_to_idx['<bos>']] + src_seq[:-1]\n",
    "\n",
    "src_tensor = torch.tensor(src_seq).unsqueeze(0)  # (1, T)\n",
    "tgt_tensor = torch.tensor(tgt_seq).unsqueeze(0)  # (1, T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e120e4a4",
   "metadata": {},
   "source": [
    "décodage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (projet2_venv)",
   "language": "python",
   "name": "projet2_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
