{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a54c22",
   "metadata": {},
   "source": [
    "# Projet 2 - NLP : Génération de texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37589ae3",
   "metadata": {},
   "source": [
    "## Étape 1 : Préparation du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c343ebb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mmf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Importer les librairies\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "\n",
    "# Télécharger les ressources NLTK si besoin\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc7b511c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu du corpus :\n",
      "Two roads diverged in a yellow wood,\n",
      "And sorry I could not travel both\n",
      "And be one traveler, long I stood\n",
      "And looked down one as far as I could\n",
      "To where it bent in the undergrowth;\n",
      "\n",
      "I wandered lonely as a cloud\n",
      "That floats on high o'er vales and hills,\n",
      "When all at once I saw a crowd,\n",
      "A host, of golden daffodils;\n",
      "Beside the lake, beneath the trees,\n",
      "Fluttering and dancing in the breeze.\n",
      "\n",
      "Hope is the thing with feathers\n",
      "That perches in the soul,\n",
      "And sings the tune without the words,\n",
      "And never stops \n"
     ]
    }
   ],
   "source": [
    "#2. Charger et prévisualiser le corpus\n",
    "with open('data/poems.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(\"Aperçu du corpus :\")\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fff9fc9",
   "metadata": {},
   "source": [
    "## Étape 2 : Tokenisation et vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c7c698f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tokens : 153\n",
      "Premiers 20 tokens : ['Two', 'roads', 'diverged', 'in', 'a', 'yellow', 'wood', ',', 'And', 'sorry', 'I', 'could', 'not', 'travel', 'both', 'And', 'be', 'one', 'traveler', ',']\n"
     ]
    }
   ],
   "source": [
    "#3. Tokenisation\n",
    "tokens = word_tokenize(text)\n",
    "print(f\"Nombre de tokens : {len(tokens)}\")\n",
    "print(f\"Premiers 20 tokens : {tokens[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d4f53f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire : 101\n",
      "Indices exemple : [17, 69, 40, 51, 19, 99, 97, 0, 6, 75]\n"
     ]
    }
   ],
   "source": [
    "# 4. Construire le vocabulaire et les mappings\n",
    "vocab = sorted(set(tokens))\n",
    "print(f\"Taille du vocabulaire : {len(vocab)}\")\n",
    "\n",
    "token_to_idx = {tok: idx for idx, tok in enumerate(vocab)}\n",
    "idx_to_token = {idx: tok for tok, idx in token_to_idx.items()}\n",
    "\n",
    "# Exemple de conversion tokens → indices\n",
    "indices = [token_to_idx[tok] for tok in tokens[:10]]\n",
    "print(f\"Indices exemple : {indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6172384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 tokens les plus fréquents : [(',', 10), ('the', 9), ('And', 6), ('I', 6), ('a', 5), ('in', 4), ('as', 3), (';', 3), ('and', 3), ('all', 3)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Analyse simple : fréquence des tokens\n",
    "counter = Counter(tokens)\n",
    "most_common = counter.most_common(10)\n",
    "print(\"10 tokens les plus fréquents :\", most_common)\n",
    "\n",
    "words, counts = zip(*most_common)\n",
    "plt.bar(words, counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed55abfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple d'entrée (indices) : [17, 69, 40, 51, 19]\n",
      "Exemple de cible (index) : 99\n"
     ]
    }
   ],
   "source": [
    "# 6. Préparer les séquences pour le modèle\n",
    "# Taille des séquences d'entrée\n",
    "seq_length = 5\n",
    "\n",
    "# Conversion complète des tokens en indices\n",
    "indices = [token_to_idx[tok] for tok in tokens]\n",
    "\n",
    "# Préparer les séquences d'entrée (X) et la cible (Y)\n",
    "inputs = []\n",
    "targets = []\n",
    "for i in range(len(indices) - seq_length):\n",
    "    inputs.append(indices[i:i+seq_length])\n",
    "    targets.append(indices[i+seq_length])\n",
    "\n",
    "print(f\"Exemple d'entrée (indices) : {inputs[0]}\")\n",
    "print(f\"Exemple de cible (index) : {targets[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f97eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Dataset et DataLoader PyTorch\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.inputs[idx]), torch.tensor(self.targets[idx])\n",
    "\n",
    "dataset = TextDataset(inputs, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33bb6d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Définir un modèle RNN simple\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        out, _ = self.rnn(embedded)\n",
    "        out = out[:, -1, :]  # dernière sortie RNN\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 32\n",
    "hidden_dim = 64\n",
    "\n",
    "model = RNNModel(vocab_size, embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2b25bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 4.6339\n",
      "Epoch 2/5 - Loss: 4.4774\n",
      "Epoch 3/5 - Loss: 4.3450\n",
      "Epoch 4/5 - Loss: 4.2117\n",
      "Epoch 5/5 - Loss: 4.0982\n"
     ]
    }
   ],
   "source": [
    "# 9. Entraînement rapide\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_inputs, batch_targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05fafa86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte généré :\n",
      "Two roads diverged in a Shall , trees tune wood When That more . May crowd lake lovely where in That undergrowth I wandered feathers ; crowd all looked where never it floats sorry darling\n"
     ]
    }
   ],
   "source": [
    "# 10. Génération de texte simple\n",
    "def generate_text(model, start_seq, idx_to_token, token_to_idx, length=20):\n",
    "    model.eval()\n",
    "    generated = start_seq.copy()\n",
    "    \n",
    "    for _ in range(length):\n",
    "        # Préparer la séquence en indices\n",
    "        seq_indices = [token_to_idx.get(tok, 0) for tok in generated[-seq_length:]]\n",
    "        seq_tensor = torch.tensor(seq_indices).unsqueeze(0)  # batch=1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(seq_tensor)\n",
    "            prob = nn.functional.softmax(output, dim=1)\n",
    "            next_idx = torch.multinomial(prob, num_samples=1).item()\n",
    "            next_tok = idx_to_token[next_idx]\n",
    "            generated.append(next_tok)\n",
    "    \n",
    "    return ' '.join(generated)\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "start_seq = tokens[:seq_length]\n",
    "print(\"Texte généré :\")\n",
    "print(generate_text(model, start_seq, idx_to_token, token_to_idx, length=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2da34cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de séquences: 148\n",
      "Exemple de séquence (indices): [17, 69, 40, 51, 19]\n",
      "Token cible pour cette séquence: 99 (yellow)\n"
     ]
    }
   ],
   "source": [
    "# Préparer les séquences d’entraînement (input / target) pour génération de texte\n",
    "# Taille des séquences (exemple 5 tokens par séquence)\n",
    "seq_length = 5\n",
    "\n",
    "# Préparer les séquences (X) et les cibles (Y)\n",
    "input_sequences = []\n",
    "target_tokens = []\n",
    "\n",
    "for i in range(len(tokens) - seq_length):\n",
    "    seq_in = tokens[i:i + seq_length]\n",
    "    seq_out = tokens[i + seq_length]\n",
    "    input_sequences.append([token_to_idx[tok] for tok in seq_in])\n",
    "    target_tokens.append(token_to_idx[seq_out])\n",
    "\n",
    "print(f\"Nombre de séquences: {len(input_sequences)}\")\n",
    "print(f\"Exemple de séquence (indices): {input_sequences[0]}\")\n",
    "print(f\"Token cible pour cette séquence: {target_tokens[0]} ({idx_to_token[target_tokens[0]]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dfa408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Créer un Dataset et DataLoader PyTorch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "dataset = TextDataset(input_sequences, target_tokens)\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9524463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définir un modèle RNN simple avec embeddings\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)               # (batch, seq_len, embed_dim)\n",
    "        output, hidden = self.rnn(x)       # output: (batch, seq_len, hidden_dim)\n",
    "        out = self.fc(output[:, -1, :])    # prendre sortie du dernier pas de temps\n",
    "        return out\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 64\n",
    "hidden_dim = 128\n",
    "model = SimpleRNNModel(vocab_size, embed_dim, hidden_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "506b59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurer la fonction de perte et l’optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e131fa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 4.6261\n",
      "Epoch 2/10, Loss: 4.3611\n",
      "Epoch 3/10, Loss: 4.1300\n",
      "Epoch 4/10, Loss: 3.9053\n",
      "Epoch 5/10, Loss: 3.6900\n",
      "Epoch 6/10, Loss: 3.4791\n",
      "Epoch 7/10, Loss: 3.2204\n",
      "Epoch 8/10, Loss: 3.0200\n",
      "Epoch 9/10, Loss: 2.8263\n",
      "Epoch 10/10, Loss: 2.6202\n"
     ]
    }
   ],
   "source": [
    "#Entraîner le modèle (exemple de boucle sur 10 epochs)\n",
    "epochs = 10\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_inputs, batch_targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfcc497d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte généré :\n",
      "Two roads diverged in a yellow wood , And sorry I could To where it bent in the undergrowth , And sorry I could To\n"
     ]
    }
   ],
   "source": [
    "#Génération de texte avec le modèle entraîné\n",
    "model.eval()\n",
    "\n",
    "def generate_text(model, start_seq, length=20):\n",
    "    model.eval()\n",
    "    tokens_generated = start_seq.copy()\n",
    "    for _ in range(length):\n",
    "        input_seq = [token_to_idx.get(tok, 0) for tok in tokens_generated[-seq_length:]]\n",
    "        input_tensor = torch.tensor([input_seq], dtype=torch.long)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            predicted_idx = output.argmax(dim=1).item()\n",
    "            tokens_generated.append(idx_to_token[predicted_idx])\n",
    "    return ' '.join(tokens_generated)\n",
    "\n",
    "# Exemple avec une séquence de départ\n",
    "start_sequence = tokens[:seq_length]\n",
    "print(\"Texte généré :\")\n",
    "print(generate_text(model, start_sequence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268b905",
   "metadata": {},
   "source": [
    "## Étape 3 : Embedding + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dff7e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définir un modèle LSTM simple avec embedding\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.lstm(x, hidden)\n",
    "        logits = self.fc(output)\n",
    "        return logits, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e80b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialiser le modèle, optimiser et loss function\n",
    "vocab_size = len(vocab)\n",
    "embed_size = 128\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "\n",
    "model = LSTMModel(vocab_size, embed_size, hidden_size, num_layers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f00b1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement (boucle sur epochs) et Génération de texte avec le modèle entraîné\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fc961e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des séquences (exemple simple)\n",
    "seq_length = 10\n",
    "\n",
    "def create_sequences(tokens, seq_length):\n",
    "    indices = [token_to_idx[t] for t in tokens]\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(len(indices) - seq_length):\n",
    "        inputs.append(indices[i:i+seq_length])\n",
    "        targets.append(indices[i+1:i+seq_length+1])\n",
    "    return torch.tensor(inputs), torch.tensor(targets)\n",
    "\n",
    "inputs, targets = create_sequences(tokens, seq_length)\n",
    "\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "776ccb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation modèle, optimizer, loss (à adapter si déjà défini)\n",
    "vocab_size = len(vocab)\n",
    "embed_size = 128\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "\n",
    "model = LSTMModel(vocab_size, embed_size, hidden_size, num_layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "epochs = 10\n",
    "print_every = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(x_batch)  # output shape: (batch, seq_len, vocab_size)\n",
    "        output = output.view(-1, vocab_size)\n",
    "        y_batch = y_batch.view(-1)\n",
    "\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % print_every == 0:\n",
    "            avg_loss = running_loss / print_every\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Step {i+1}/{len(dataloader)}, Loss: {avg_loss:.4f}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b192ad76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texte généré :\n",
      " Two roads diverged in a the , And , I . the the May , , all dancing the the , stops and ; ; the lake , a , of ; wandered ; the beneath , beneath the trees , Fluttering dancing in the the dancing . is the is thing and ; in\n"
     ]
    }
   ],
   "source": [
    "# Génération de texte avec le modèle entraîné\n",
    "model.eval()\n",
    "\n",
    "def generate_text(model, start_text, length=50, temperature=1.0):\n",
    "    model.eval()\n",
    "    tokens_generated = []\n",
    "    input_seq = [token_to_idx.get(t, 0) for t in start_text.split()]\n",
    "    input_seq = input_seq[-seq_length:]  # s'assurer que la séquence est <= seq_length\n",
    "\n",
    "    hidden = None\n",
    "    for _ in range(length):\n",
    "        x = torch.tensor(input_seq).unsqueeze(0).to(device)  # (1, seq_len)\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model(x, hidden)\n",
    "\n",
    "        logits = output[0, -1] / temperature  # logits du dernier token prédit\n",
    "        probs = F.softmax(logits, dim=0).cpu().numpy()\n",
    "        next_token_idx = np.random.choice(len(probs), p=probs)\n",
    "        tokens_generated.append(idx_to_token[next_token_idx])\n",
    "\n",
    "        input_seq.append(next_token_idx)\n",
    "        input_seq = input_seq[1:]  # glisser la fenêtre\n",
    "\n",
    "    return \" \".join(tokens_generated)\n",
    "\n",
    "start_phrase = \"Two roads diverged in a\"\n",
    "generated = generate_text(model, start_phrase, length=50, temperature=0.8)\n",
    "print(\"\\nTexte généré :\\n\", start_phrase + \" \" + generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6a39ad",
   "metadata": {},
   "source": [
    "# Étape 4 : Modèle RNN avec encodage One-hot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (projet2_venv)",
   "language": "python",
   "name": "projet2_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
